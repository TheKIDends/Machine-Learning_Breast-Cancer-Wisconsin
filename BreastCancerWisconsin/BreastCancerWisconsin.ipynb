{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 1: Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "dataset link: [Breast Cancer Wisconsin](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing the libraries and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylFhvz9XzuGI"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('./data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dealing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = dataset.drop(labels=\"Unnamed: 32\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(0, dataset.shape[0]):\n",
        "    if dataset.iloc[i, 1] == 'M':\n",
        "        dataset.iloc[i, 1] = 1\n",
        "    else:\n",
        "        dataset.iloc[i, 1] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting the training data and testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_set = dataset.iloc[:, 2:].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_set = dataset.iloc[:, 1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_set.shape, y_set.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_set, y_set, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sc = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 2: Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x.astype(float)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model(x, w, b):\n",
        "  out = sigmoid(np.dot(x, w) + b)\n",
        "  return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Binary cross entropy\n",
        "def bce_loss(yhat, y):\n",
        "    m = len(y)\n",
        "    eps = 1e-9\n",
        "    return -np.sum(y * np.log(yhat + eps) + (1 - y) * np.log(1 - yhat + eps)) / m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gradient(x, y_hat, y):\n",
        "  m = len(y)\n",
        "  grad_w = np.dot(x.T, y_hat-y) / m\n",
        "  grad_b = np.sum(y_hat-y) / m\n",
        "  return grad_w, grad_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(x, y, n_epoch=100000, lr=1e-3):\n",
        "  m, d = x.shape\n",
        "  w = np.zeros(d)\n",
        "  b = np.zeros(1)\n",
        "\n",
        "  for epoch in range(n_epoch):\n",
        "    y_hat = model(x, w, b)\n",
        "    loss = bce_loss(y_hat, y)\n",
        "    \n",
        "    grad_w, grad_b = gradient(x, y_hat, y)\n",
        "\n",
        "    w = w - lr * grad_w\n",
        "    b = b - lr * grad_b\n",
        "\n",
        "    if epoch % (n_epoch/100) == 0 or epoch == n_epoch-1:\n",
        "      print(f\"epoch {epoch}: train_loss = {loss:.4f}\")\n",
        "\n",
        "  return w, bs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 26000: train_loss = 0.4164\n",
            "epoch 26500: train_loss = 0.4138\n",
            "epoch 27000: train_loss = 0.4112\n",
            "epoch 27500: train_loss = 0.4086\n",
            "epoch 28000: train_loss = 0.4061\n",
            "epoch 28500: train_loss = 0.4037\n"
          ]
        }
      ],
      "source": [
        "w_optim, b_optim = train_model(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_trained_model(x_test, y_test, w, b):\n",
        "  y_hat = model(x_test, w, b)\n",
        "  loss = bce_loss(y_hat, y_test)\n",
        "  print(f\"test_loss = {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_trained_model(x_test, y_test, w_optim, b_optim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(y_hat, y):\n",
        "    threshold = 0.9\n",
        "    acc = 1\n",
        "    for i in range(len(y)):\n",
        "        if y[i] == 1:\n",
        "            if y_hat[i] >= threshold:\n",
        "                y_hat[i] = y[i]\n",
        "                acc += 1\n",
        "        else:\n",
        "            if y_hat[i] < threshold:\n",
        "                y_hat[i] = y[i]\n",
        "                acc += 1\n",
        "    return acc / len(y) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_hat = model(x_test, w_optim, b_optim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy(y_hat, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "regression",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e0144baad0ecee903f108a3e46e51ceadd7da3fc904cfa79747d813b61464b4e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
